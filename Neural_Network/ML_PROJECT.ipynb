{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GpsbFJsQGxz"
   },
   "source": [
    "## **1. GROUP MEMBERS(Name AND Roll number)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtsEweacPiv-"
   },
   "source": [
    "**Ashutosh**(20/49052)\n",
    "\n",
    "**Monu Kumar**(20/49022)\n",
    "\n",
    "**Shambhu**(20/49073)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sDWqS9HRdnJ"
   },
   "source": [
    "## **2. MOBILE PRICE CLASSIFICATION**\n",
    "\n",
    "> **SOURCE**:-https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification?select=test.csv\n",
    "\n",
    "\n",
    "> **DESCRIPTION**:-\n",
    "IN the given dataset **Mobile Price Classification** \n",
    "There are 20 attributes(Columns) and 1 classification attributes having 4 classes((low cost=0), (medium cost=1), (high cost=2) and (very high cost=4)) and 2000 records.\n",
    "\n",
    "**According to the attributes we predict the class of the mobile phone.**\n",
    ">Attributes(Columns):-\n",
    "  1. **battery_power**(Total energy a battery can store in one time measured in mAh).\n",
    "  2. **blue**(Has bluetooth or not).\n",
    "  3. **clock_speed**(speed at which microprocessor executes instructions)\n",
    "  4. **dual_sim**(Has dual sim support or not).\n",
    "  5. **fc**(Front Camera mega pixels).\n",
    "  6. **four_g**(Has 4G or not).\n",
    "  7. **int_memory**(Internal Memory in Gigabytes)\n",
    "  8. **m_dep**(Mobile Depth in cm).\n",
    "  9. **mobile_wt**(Weight of mobile phone).\n",
    "  10. **n_cores**(Number of cores of processor).\n",
    "  11. **pc**(Primary Camera mega pixels).\n",
    "  12. **px_height**(Pixel Resolution Height).\n",
    "  13. **px_width**(Pixel Resolution Width).\n",
    "  14. **ram**(Random Access Memory in Mega Bytes)\n",
    "  15. **sc_h**(Screen Height of mobile in cm).\n",
    "  16. **sc_w**(Screen Width of mobile in cm).\n",
    "  17. **talk_time**(longest time that a single battery charge will last when you are).\n",
    "  18. **three_g**(Has 3G or not).\n",
    "  19. **touch_screen**(Has touch screen or not).\n",
    "  20. **wifi**(Has wifi or not).\n",
    "  21. **price_range(This is the target variable with value of 0(low cost), 1(medium cost), 2(high cost) and 3(very high cost).)**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "524M97klkITs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000249F043BCD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/fabulous/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000249F059EB10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/fabulous/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000249F059F550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/fabulous/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000249F059FED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/fabulous/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000249F05B0910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/fabulous/\n",
      "ERROR: Could not find a version that satisfies the requirement fabulous (from versions: none)\n",
      "ERROR: No matching distribution found for fabulous\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fabulous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_subplots\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfabulous\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text \u001b[38;5;28;01mas\u001b[39;00m ft\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fabulous'"
     ]
    }
   ],
   "source": [
    "# LIBRARIES\n",
    "!pip install fabulous\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from fabulous import text as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxtWP8PZU4SW"
   },
   "outputs": [],
   "source": [
    "import pprint as pprint\n",
    "import seaborn as sns\n",
    "from fabulous.color import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QyvvALFlvQ4",
    "outputId": "c94eedce-985b-40c7-b42c-7ceeb9f0ac06"
   },
   "outputs": [],
   "source": [
    "#READ CSV FILE\n",
    "df_Original=pd.read_csv(\"train.csv\")\n",
    "print(bold(yellow(df_Original)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKXoesMVmZ-u",
    "outputId": "50db7889-267a-4359-d359-30caf334aa4e"
   },
   "outputs": [],
   "source": [
    "#Describe\n",
    "print(bold(blue(df_Original.describe())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMW5ZwK1DWTh",
    "outputId": "da1c5219-c72e-4020-b706-ddd2bf3022c6"
   },
   "outputs": [],
   "source": [
    "#INFO\n",
    "print(bold(magenta(df_Original.info())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OY5oDccGWGJ4",
    "outputId": "12110183-259e-405e-c7ba-c19741415e49"
   },
   "outputs": [],
   "source": [
    "#HEAD\n",
    "print(bold(df_Original.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnabul6IWJaF",
    "outputId": "577553aa-d14f-4412-dd0c-27c1e8b80c86"
   },
   "outputs": [],
   "source": [
    "#TAIL\n",
    "print(bold(df_Original.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVuECKYwWmjn",
    "outputId": "7f49be82-6212-4304-8cc2-eb1f25c0768d"
   },
   "outputs": [],
   "source": [
    "#INDEX | COLUMNS\n",
    "print(bold(red(df_Original.columns)))\n",
    "print(blue(df_Original.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQQepnONOHL8",
    "outputId": "8b644607-4bc2-4e0e-f6eb-47931f5d8341"
   },
   "outputs": [],
   "source": [
    "#DIMENSION\n",
    "print(bold(yellow(\"Dimension of Orignal data : \",np.ndim(df_Original))))\n",
    "print(bold(red(\"Shape of Orignal data : \",np.shape(df_Original))))\n",
    "print(bold(cyan(\"Type : \",type(df_Original))))\n",
    "print(bold(magenta(\"DataTypes --->\\n\",df_Original.dtypes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3h_flhfyYoC",
    "outputId": "65ff17a1-30e6-47bf-8976-45d4d580a268"
   },
   "outputs": [],
   "source": [
    "#Check NULL Values\n",
    "print(bold(green(df_Original.isnull().sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylbK1Qc0aq90"
   },
   "source": [
    "# **3. Exploratory Data Analysis**\n",
    "\n",
    "> **1.1 Data Distribution frequecy plots.\n",
    "      (HISTOGRAM)**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S5Nvt7nI1gV-",
    "outputId": "bec62800-5fda-4196-87c6-180acbdcd9fc"
   },
   "outputs": [],
   "source": [
    "df_Original.hist(bins=30,figsize=(25, 15) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HelieyVbYWkC"
   },
   "source": [
    ">**1.2 Scatter plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Wes4qTBZa_9j",
    "outputId": "ddf1a9de-ce42-42dc-ca42-492aef754bd0"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_Original,height=3,aspect=0.4,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf-yU9ElYgH2"
   },
   "source": [
    ">**1.3 Pearson correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqyTp31KSmfy"
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(df_Original.corr(),cmap=\"RdYlBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "PZa35CZEuNPR",
    "outputId": "cc610d81-3a73-4d5e-b09c-023005912a42"
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(df_Original.corr())\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIRpEI2KigiB",
    "outputId": "1ed1b9c1-198d-48f1-8b81-df6ba72ef793"
   },
   "outputs": [],
   "source": [
    "print(\"Top 10 corelated Columns to the Tagated value : \")\n",
    "abs(df_Original.corr()[\"price_range\"]).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbFsX5EADdVB"
   },
   "outputs": [],
   "source": [
    "#Attribute Classification\n",
    "Independent_Attributes=df_Original[df_Original.corr()[\"price_range\"].nlargest(10).index[1:]]\n",
    "Dependent_Attribute=df_Original.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fupYaKCBMRQ_",
    "outputId": "1a0d3885-13ca-49b3-bbfe-88a6419cb9d1"
   },
   "outputs": [],
   "source": [
    "print(\"Independent Attributes are :- /n\")\n",
    "print(Independent_Attributes.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGrkJzpgUXW9"
   },
   "source": [
    "**SCATTER PLOT OF INDEPENDENT ATTRIBUTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rgZy3KCzkC7m",
    "outputId": "bf291ffb-9779-4a4f-c9e8-457375f4e47c"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(Independent_Attributes, dimensions=(Independent_Attributes), height=1500, width=2500)\n",
    "\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1QCUBGOUjRo"
   },
   "source": [
    "**PEARSON CORELATION OF INDEPENDENT ATTRIBUTES:-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "-4BCdTgbUrVM",
    "outputId": "ec2ff468-4bb7-4dc6-a976-1dbc0f53a6a9"
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(Independent_Attributes.corr())\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A41YtT6LN5Sc",
    "outputId": "61f020b2-11e5-4d74-d643-d89a22bee0fd"
   },
   "outputs": [],
   "source": [
    "print(\"Dependent Attribute is :- \\n\")\n",
    "print(Dependent_Attribute.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LM7ts5UogEI",
    "outputId": "f4f8a3e5-4229-4795-8718-d944c0a7d0d0"
   },
   "outputs": [],
   "source": [
    "Dependent_Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMffH5UXaneF"
   },
   "source": [
    "# **2.1 Removing Duplicate values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "o0jIXE6eY9q9",
    "outputId": "a43f8f26-a4bb-4c11-9dee-16c4b292bde8"
   },
   "outputs": [],
   "source": [
    "Duplicates_value=df_Original[Independent_Attributes.duplicated()]\n",
    "Duplicates_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpt0_D7tbdCC"
   },
   "source": [
    "# **2.2 Handling Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "9TWpp-RLbNrD",
    "outputId": "8e225a40-e416-4a28-bcd2-428e002b3db4"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for col in df_Original:\n",
    "  fig.add_trace(go.Box(y=df_Original[col].values, name=df_Original[col].name))\n",
    "  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "400kRqoMvUSs"
   },
   "source": [
    "##**2.3 Handling Null values (K-nearest neighbour method)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAh7wffmvSbD",
    "outputId": "32f391b5-c4b4-4c45-cde7-278be58c7c38"
   },
   "outputs": [],
   "source": [
    "print(df_Original.isna().sum(),bold(yellow(\"\\n\\n\\n NO NULL VALUE PRESENT :-\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWXi-T2BzCZD"
   },
   "source": [
    "##**3. Feature Scaling**\n",
    "\n",
    "> **3.1 STANDARD SCALER**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIJRlo5Gb7-I"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def normalize(Independent_Attributes):\n",
    "        print(\"Mean and Standard Deviation Before\")\n",
    "        print(Independent_Attributes.mean(axis=0), Independent_Attributes.std(axis=0))\n",
    "        \n",
    "        sc=StandardScaler()\n",
    "        XScaled = sc.fit_transform(Independent_Attributes)\n",
    "        \n",
    "        print(\"Mean and Standard Deviation After\")\n",
    "        print(XScaled.mean(axis=0).round(4), XScaled.std(axis=0))\n",
    "        return XScaled\n",
    "\n",
    "# Standard=normalize(Independent_Attributes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irY_Ud8Y30V3"
   },
   "source": [
    "##**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DhKMimzfu4Zq",
    "outputId": "e9b8836c-f011-4735-adf3-1401c783ab6e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn .metrics import roc_auc_score\n",
    "def Logistic_Regression(Independent_Attributes,Dependent_Attribute):\n",
    "  X=Independent_Attributes.values\n",
    "  Y=Dependent_Attribute.values\n",
    "  print(\"*************Normalization/Standardization*************\")\n",
    "  XScaled = normalize(X) \n",
    "\n",
    "  skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "  acc=[]\n",
    "\n",
    "  y_ori = np.array([], dtype=int)\n",
    "\n",
    "  y_pre= np.array([], dtype=int)\n",
    "  net_mat=np.zeros((4, 4))\n",
    "  roc=[]\n",
    "  for train_index, test_index in skf.split(X,Y):\n",
    "      \n",
    "      X_train=X[train_index]\n",
    "      X_test=X[test_index]\n",
    "      Y_train=Y[train_index]\n",
    "      Y_test=Y[test_index] \n",
    "      print(bold(green(\"Shape of X_train:-   {}   ||   X_test:-   {}   || Y_train:-  {}  ||  Y_test:-   {}  \".format(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)))) \n",
    "       \n",
    "      print(bold(magenta(\"Train:-   {}   ||  Test:-    {} \".format(np.bincount(Y[train_index]),np.bincount(Y[test_index]))))) \n",
    "          \n",
    "      LRModel = LogisticRegression(max_iter=100000)\n",
    "      LRModel.fit(X_train, Y_train)\n",
    "      Y_testPred = LRModel.predict(X_test)\n",
    "\n",
    "      y_ori=np.hstack((y_ori,Y_test))\n",
    "      \n",
    "  \n",
    "      y_pre=np.hstack((y_pre,Y_testPred))   \n",
    "      testAccuracy = metrics.accuracy_score(Y_test, Y_testPred)\n",
    "      print(bold(red(\"Test Accuracy\", testAccuracy*100)))\n",
    "      acc.append(testAccuracy)\n",
    "      roc_score=roc_auc_score(Y_test, LRModel.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "      print(bold(yellow(\"ROC_AUC_SCORE: \",roc_score)))\n",
    "    \n",
    "\n",
    "      matrix1= confusion_matrix(Y_test, Y_testPred)\n",
    "      #      sum of the total confusion matirx\n",
    "      net_mat=net_mat+matrix1\n",
    "      \n",
    "      plot_confusion_matrix(matrix1,show_normed=True, colorbar=True, show_absolute=True)   \n",
    "      \n",
    "      plt.show()\n",
    "  print(bold(green(\" Result Of Logsitic Regression: \\n\")))\n",
    "  avg_accuracy=(sum(acc) / len(acc))*100\n",
    "  print(bold(yellow_bg(\"average accuracy:  \",avg_accuracy )))       \n",
    "\n",
    "  net_mat = net_mat.astype('int')\n",
    "  print(bold(cyan(net_mat)))\n",
    "  plot_confusion_matrix(net_mat,show_normed=True, colorbar=True, show_absolute=True, cmap='Blues')   \n",
    "\n",
    "  plt.show()\n",
    "   \n",
    "  roc_score=roc_auc_score(Y, LRModel.predict_proba(X), multi_class='ovr')\n",
    "\n",
    "  print(bold(yellow_bg(\"ROC_AUC_SCORE: \",roc_score)))\n",
    " \n",
    "  \n",
    "  \n",
    "  print(\"Classification Report:\\n\")\n",
    "  report=classification_report(y_ori, y_pre,output_dict=True)\n",
    "  report_Df=pd.DataFrame(report)\n",
    "  print(report_Df)\n",
    "  sns.heatmap(report_Df.T,annot=True)\n",
    "  return avg_accuracy\n",
    "avg_accuracy_logistic=Logistic_Regression(Independent_Attributes,Dependent_Attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnXlH4en3_vx"
   },
   "source": [
    "###**Descision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jZoJxa8ecLhn",
    "outputId": "c89cb9b7-2f3c-4470-be70-dd55279486ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "def Decision_Tree(Independent_Attributes,Dependent_Attribute):\n",
    "  X=Independent_Attributes.values\n",
    "  Y=Dependent_Attribute.values\n",
    "  print(\"*************Normalization/Standardization*************\")\n",
    "  XScaled = normalize(X) \n",
    "\n",
    "  skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "  acc=[]\n",
    "\n",
    "  y_ori = np.array([], dtype=int)\n",
    "\n",
    "  y_pre= np.array([], dtype=int)\n",
    "  net_mat=np.zeros((4, 4))\n",
    "  \n",
    "  for train_index, test_index in skf.split(X,Y):\n",
    "      \n",
    "      X_train=X[train_index]\n",
    "      X_test=X[test_index]\n",
    "      Y_train=Y[train_index]\n",
    "      Y_test=Y[test_index]\n",
    "      print(bold(green(\"Shape of X_train:-   {}   ||   X_test:-   {}   || Y_train:-  {}  ||  Y_test:-   {}  \".format(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape))))\n",
    "        \n",
    "      print(bold(magenta(\"Train:-   {}   ||  Test:-    {} \".format(np.bincount(Y[train_index]),np.bincount(Y[test_index])))))\n",
    "      treemodel=DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "      treemodel.fit(X_train, Y_train)\n",
    "\n",
    "      Y_testPred =treemodel.predict(X_test)\n",
    "\n",
    "      y_ori=np.hstack((y_ori,Y_test))\n",
    "      \n",
    "  \n",
    "      y_pre=np.hstack((y_pre,Y_testPred))   \n",
    "      testAccuracy = metrics.accuracy_score(Y_test, Y_testPred)\n",
    "      print(bold(red(\"Test Accuracy\", testAccuracy*100)))\n",
    "      acc.append(testAccuracy)\n",
    "\n",
    "      roc_score=roc_auc_score(Y_test, treemodel.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "      print(bold(yellow(\"ROC_AUC_SCORE: \",roc_score))) \n",
    "     \n",
    "\n",
    "      matrix1= confusion_matrix(Y_test, Y_testPred)\n",
    "      #      sum of the total confusion matirx\n",
    "      net_mat=net_mat+matrix1\n",
    "     \n",
    "      \n",
    "      plot_confusion_matrix(matrix1,show_normed=True, colorbar=True, show_absolute=True)   \n",
    "      \n",
    "      plt.show()\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "      \n",
    "      plt.figure(figsize=(15,10))\n",
    "      tree.plot_tree(treemodel,feature_names=Independent_Attributes.columns,filled=True)\n",
    "      \n",
    "    \n",
    "  print(bold(green(\" Result Of  Decisiom Tree: \\n\")))\n",
    "  avg_accuracy=(sum(acc) / len(acc))*100\n",
    "  print(bold(yellow_bg(\"average accuracy:  \",avg_accuracy )))     \n",
    "\n",
    "  net_mat = net_mat.astype('int')\n",
    "  print(bold(cyan(net_mat)))\n",
    "  plot_confusion_matrix(net_mat,show_normed=True, colorbar=True, show_absolute=True, cmap='Blues')   \n",
    "\n",
    "  plt.show()\n",
    "   \n",
    "  roc_score=roc_auc_score(Y, treemodel.predict_proba(X), multi_class='ovr')\n",
    "  print(bold(yellow_bg(\"ROC_AUC_SCORE: \",roc_score)))\n",
    " \n",
    "  \n",
    "  \n",
    "  print(bold(\"Classification Report:\\n\"))\n",
    "  report=classification_report(y_ori, y_pre,output_dict=True)\n",
    "  report_Df=pd.DataFrame(report)\n",
    "  print(bold(magenta(report_Df)))\n",
    "  sns.heatmap(report_Df.T,annot=True)\n",
    "  return avg_accuracy\n",
    "\n",
    "\n",
    "avg_accuracy_DCT=Decision_Tree(Independent_Attributes,Dependent_Attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dp_Or0JMQVwr"
   },
   "source": [
    "# **Gaussian Classification**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CsfsPrPZQd09",
    "outputId": "716e11e6-d642-4a5b-f62c-730b449da969"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def Gaussian_Naive_Bayes(Independent_Attributes,Dependent_Attribute):\n",
    "  X=Independent_Attributes.values\n",
    "  Y=Dependent_Attribute.values\n",
    "  print(\"*************Normalization/Standardization*************\")\n",
    "  XScaled = normalize(X) \n",
    "\n",
    "  skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "  acc=[]\n",
    "\n",
    "  y_ori = np.array([], dtype=int)\n",
    "\n",
    "  y_pre= np.array([], dtype=int)\n",
    "  net_mat=np.zeros((4, 4))\n",
    "  for train_index, test_index in skf.split(X,Y):\n",
    "      \n",
    "      X_train=X[train_index]\n",
    "      X_test=X[test_index]\n",
    "      Y_train=Y[train_index]\n",
    "      Y_test=Y[test_index]\n",
    "      print(bold(green(\"Shape of X_train:-   {}   ||   X_test:-   {}   || Y_train:-  {}  ||  Y_test:-   {}  \".format(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)))) \n",
    "        \n",
    "      print(bold(magenta(\"Train:-   {}   ||  Test:-    {} \".format(np.bincount(Y[train_index]),np.bincount(Y[test_index])))))  \n",
    "          \n",
    "      GN = GaussianNB()\n",
    "      GN.fit(X_train, Y_train)\n",
    "      Y_testPred = GN.predict(X_test)\n",
    "      \n",
    "      y_ori=np.hstack((y_ori,Y_test))\n",
    "      \n",
    "  \n",
    "      y_pre=np.hstack((y_pre,Y_testPred))\n",
    "       \n",
    "      testAccuracy = metrics.accuracy_score(Y_test, Y_testPred)\n",
    "      print(bold(red(\"Test Accuracy\", testAccuracy*100)))\n",
    "      acc.append(testAccuracy)\n",
    "\n",
    "      roc_score=roc_auc_score(Y_test, GN.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "      print(bold(yellow(\"ROC_AUC_SCORE: \",roc_score)))   \n",
    "\n",
    "      matrix1= confusion_matrix(Y_test, Y_testPred)\n",
    "      #      sum of the total confusion matirx\n",
    "      net_mat=net_mat+matrix1\n",
    "     \n",
    "      \n",
    "      plot_confusion_matrix(matrix1,show_normed=True, colorbar=True, show_absolute=True)   \n",
    "      \n",
    "      plt.show()\n",
    "  print(bold(green(\"Result Of Gaussian Naive Bayes Classifier: \\n\")))\n",
    "  print(bold(magenta(\"Naive Bayes score: \",GN.score(X_test, Y_testPred))))\n",
    "  avg_accuracy= (sum(acc) / len(acc))*100\n",
    "  print(bold(cyan_bg(\"average accuracy:  \", avg_accuracy)))    \n",
    "\n",
    "  net_mat = net_mat.astype('int')\n",
    "  print(bold(cyan(net_mat)))\n",
    "  plot_confusion_matrix(net_mat,show_normed=True, colorbar=True, show_absolute=True, cmap='Blues')   \n",
    "\n",
    "  plt.show()\n",
    "   \n",
    "  roc_score=roc_auc_score(Y,GN.predict_proba(X), multi_class='ovr')\n",
    "  print(bold(yellow_bg(\"ROC_AUC_SCORE: \",roc_score)))\n",
    " \n",
    "  \n",
    "  \n",
    "  print(\"Classification Report:\\n\")\n",
    "  report=classification_report(y_ori, y_pre,output_dict=True)\n",
    "  report_Df=pd.DataFrame(report)\n",
    "  print(bold(blue(report_Df)))\n",
    "  sns.heatmap(report_Df.T,annot=True)\n",
    "  return avg_accuracy\n",
    "avg_accuracy_GNB=Gaussian_Naive_Bayes(Independent_Attributes,Dependent_Attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11wZWEVOihjy"
   },
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xNGj0-nqinFF",
    "outputId": "8fe92c81-6803-4d44-e5f6-5343da8b9e2e"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def KNN(Independent_Attributes,Dependent_Attribute):\n",
    "  X=Independent_Attributes.values\n",
    "  Y=Dependent_Attribute.values\n",
    "  print(\"*************Normalization/Standardization*************\")\n",
    "  XScaled = normalize(X) \n",
    "\n",
    "  skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "  acc=[]\n",
    "\n",
    "  y_ori = np.array([], dtype=int)\n",
    "\n",
    "  y_pre= np.array([], dtype=int)\n",
    "  net_mat=np.zeros((4, 4))\n",
    "  for train_index, test_index in skf.split(X,Y):\n",
    "      \n",
    "      X_train=X[train_index]\n",
    "      X_test=X[test_index]\n",
    "      Y_train=Y[train_index]\n",
    "      Y_test=Y[test_index]  \n",
    "      print(bold(green(\"Shape of X_train:-   {}   ||   X_test:-   {}   || Y_train:-  {}  ||  Y_test:-   {}  \".format(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)))) \n",
    "      print(bold(magenta(\"Train:-   {}   ||  Test:-    {} \".format(np.bincount(Y[train_index]),np.bincount(Y[test_index])))))\n",
    "      \n",
    "      Kn = KNeighborsClassifier(n_neighbors=10)\n",
    "      Kn.fit(X_train, Y_train)\n",
    "      Y_testPred = Kn.predict(X_test)\n",
    "\n",
    "      y_ori=np.hstack((y_ori,Y_test))\n",
    "      \n",
    "  \n",
    "      y_pre=np.hstack((y_pre,Y_testPred))\n",
    "       \n",
    "      testAccuracy = metrics.accuracy_score(Y_test, Y_testPred)\n",
    "      \n",
    "      \n",
    "      print(bold(red(\"Test Accuracy\", testAccuracy*100)))\n",
    "      acc.append(testAccuracy)\n",
    "\n",
    "      roc_score=roc_auc_score(Y_test, Kn.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "      print(bold(yellow(\"ROC_AUC_SCORE: \",roc_score)))\n",
    "    \n",
    "\n",
    "      matrix1= confusion_matrix(Y_test, Y_testPred)\n",
    "      # sum of the total confusion matirx\n",
    "      net_mat=net_mat+matrix1\n",
    "     \n",
    "      \n",
    "      plot_confusion_matrix(matrix1,show_normed=True, colorbar=True, show_absolute=True)   \n",
    "      \n",
    "      plt.show()\n",
    "  avg_accuracy=(sum(acc) / len(acc))*100\n",
    "  print(bold(yellow_bg(\"average accuracy:  \", avg_accuracy)))       \n",
    "\n",
    "  net_mat = net_mat.astype('int')\n",
    "  print(bold(cyan(net_mat)))\n",
    "  plot_confusion_matrix(net_mat,show_normed=True, colorbar=True, show_absolute=True, cmap='Blues')   \n",
    "\n",
    "  plt.show()\n",
    "   \n",
    "  roc_score=roc_auc_score(Y,Kn.predict_proba(X), multi_class='ovr')\n",
    "  print(bold(yellow_bg(\"ROC_AUC_SCORE: \",roc_score)))\n",
    " \n",
    " \n",
    "  \n",
    "  print(bold(\"Classification Report:\\n\"))\n",
    "  report=classification_report(y_ori, y_pre,output_dict=True)\n",
    "  report_Df=pd.DataFrame(report)\n",
    "  print(bold(blue(report_Df)))\n",
    "  sns.heatmap(report_Df.T,annot=True)\n",
    "  return avg_accuracy\n",
    "avg_accuracy_knn=KNN(Independent_Attributes,Dependent_Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "Hy8qIGBvtQjC",
    "outputId": "5c432a07-9489-4a95-b192-b4b18483fe4b"
   },
   "outputs": [],
   "source": [
    "x=[avg_accuracy_logistic,avg_accuracy_GNB,avg_accuracy_knn,avg_accuracy_DCT]\n",
    "features=[\"avg_accuracy_logistic\",\"avg_accuracy_GNB\",\"avg_accuracy_knn\",\"avg_accuracy_DCT\"]\n",
    "d=pd.Series(x,index=features)\n",
    "df=pd.DataFrame(d,columns=[\"Accuracy\"])\n",
    "print(bold(red(df)))\n",
    "\n",
    "fig = px.bar(df, x=features, y=\"Accuracy\",title=\"Accuracy of Each Classification model\",color=\"Accuracy\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
